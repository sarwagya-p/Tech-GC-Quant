{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0 = pd.read_parquet('dataset/train_0.parquet')\n",
    "train_1 = pd.read_parquet('dataset/train_1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_parquet('dataset/train_2.parquet')\n",
    "test_df = test_df.dropna(axis=1, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1_na = train_1.dropna(axis=1, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0_na = train_0.dropna(axis=1, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_0_na, train_1_na], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>symbol_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>feature_05</th>\n",
       "      <th>feature_06</th>\n",
       "      <th>feature_07</th>\n",
       "      <th>feature_08</th>\n",
       "      <th>feature_09</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_78</th>\n",
       "      <th>target_9</th>\n",
       "      <th>target_3</th>\n",
       "      <th>target_4</th>\n",
       "      <th>target_5</th>\n",
       "      <th>target_6</th>\n",
       "      <th>target_7</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_8</th>\n",
       "      <th>target_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.112212</td>\n",
       "      <td>1.060330</td>\n",
       "      <td>1.515157</td>\n",
       "      <td>0.352634</td>\n",
       "      <td>-0.447763</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.421823</td>\n",
       "      <td>-0.293646</td>\n",
       "      <td>-0.061842</td>\n",
       "      <td>-0.305413</td>\n",
       "      <td>-0.419151</td>\n",
       "      <td>-0.111796</td>\n",
       "      <td>-0.535104</td>\n",
       "      <td>-0.044332</td>\n",
       "      <td>-0.039061</td>\n",
       "      <td>-0.744789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.760715</td>\n",
       "      <td>0.482468</td>\n",
       "      <td>1.184037</td>\n",
       "      <td>0.171099</td>\n",
       "      <td>-0.247298</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3.111076</td>\n",
       "      <td>-0.075267</td>\n",
       "      <td>-0.359360</td>\n",
       "      <td>-1.270054</td>\n",
       "      <td>-0.018332</td>\n",
       "      <td>-0.040286</td>\n",
       "      <td>-1.417509</td>\n",
       "      <td>0.085840</td>\n",
       "      <td>0.487232</td>\n",
       "      <td>-0.124533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.813596</td>\n",
       "      <td>1.020798</td>\n",
       "      <td>1.318752</td>\n",
       "      <td>0.398088</td>\n",
       "      <td>-0.247506</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458474</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.194658</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>1.583400</td>\n",
       "      <td>0.018712</td>\n",
       "      <td>-1.055035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.926893</td>\n",
       "      <td>0.510098</td>\n",
       "      <td>0.645825</td>\n",
       "      <td>0.198428</td>\n",
       "      <td>-0.129691</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>17.805511</td>\n",
       "      <td>3.336086</td>\n",
       "      <td>2.051951</td>\n",
       "      <td>2.400644</td>\n",
       "      <td>0.962730</td>\n",
       "      <td>-0.939277</td>\n",
       "      <td>1.845870</td>\n",
       "      <td>-2.372452</td>\n",
       "      <td>-1.663179</td>\n",
       "      <td>-4.585349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.665231</td>\n",
       "      <td>0.547458</td>\n",
       "      <td>1.009267</td>\n",
       "      <td>0.178444</td>\n",
       "      <td>-0.172451</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.249322</td>\n",
       "      <td>-0.707027</td>\n",
       "      <td>-0.344866</td>\n",
       "      <td>-1.248052</td>\n",
       "      <td>-0.129645</td>\n",
       "      <td>-3.145927</td>\n",
       "      <td>-0.452708</td>\n",
       "      <td>0.300044</td>\n",
       "      <td>0.489202</td>\n",
       "      <td>0.242737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_id  time_id  symbol_id    weight  feature_05  feature_06  feature_07  \\\n",
       "0      170        0          0  2.112212    1.060330    1.515157    0.352634   \n",
       "1      170        0          1  2.760715    0.482468    1.184037    0.171099   \n",
       "2      170        0          2  1.813596    1.020798    1.318752    0.398088   \n",
       "3      170        0          3  0.926893    0.510098    0.645825    0.198428   \n",
       "4      170        0          7  1.665231    0.547458    1.009267    0.178444   \n",
       "\n",
       "   feature_08  feature_09  feature_10  ...  feature_78  target_9  target_3  \\\n",
       "0   -0.447763          11           7  ...   -0.421823 -0.293646 -0.061842   \n",
       "1   -0.247298          11           7  ...    3.111076 -0.075267 -0.359360   \n",
       "2   -0.247506          81           2  ...    0.458474 -5.000000 -5.000000   \n",
       "3   -0.129691           4           3  ...   17.805511  3.336086  2.051951   \n",
       "4   -0.172451          11           7  ...   -0.249322 -0.707027 -0.344866   \n",
       "\n",
       "   target_4  target_5  target_6  target_7  target_1  target_8  target_2  \n",
       "0 -0.305413 -0.419151 -0.111796 -0.535104 -0.044332 -0.039061 -0.744789  \n",
       "1 -1.270054 -0.018332 -0.040286 -1.417509  0.085840  0.487232 -0.124533  \n",
       "2  0.194658 -5.000000 -5.000000 -5.000000  1.583400  0.018712 -1.055035  \n",
       "3  2.400644  0.962730 -0.939277  1.845870 -2.372452 -1.663179 -4.585349  \n",
       "4 -1.248052 -0.129645 -3.145927 -0.452708  0.300044  0.489202  0.242737  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for target_1...\n",
      "\n",
      "OLS Summary for target_1:\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               target_1   R-squared:                       0.015\n",
      "Model:                            OLS   Adj. R-squared:                  0.015\n",
      "Method:                 Least Squares   F-statistic:                     409.1\n",
      "Date:                Wed, 12 Feb 2025   Prob (F-statistic):               0.00\n",
      "Time:                        21:54:58   Log-Likelihood:            -1.2820e+06\n",
      "No. Observations:              972105   AIC:                         2.564e+06\n",
      "Df Residuals:                  972068   BIC:                         2.564e+06\n",
      "Df Model:                          36                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0043      0.005     -0.880      0.379      -0.014       0.005\n",
      "feature_05     0.0195      0.001     13.810      0.000       0.017       0.022\n",
      "feature_06    -0.0764      0.001    -62.676      0.000      -0.079      -0.074\n",
      "feature_07    -0.0580      0.002    -35.674      0.000      -0.061      -0.055\n",
      "feature_09 -4.458e-05   7.28e-05     -0.612      0.541      -0.000    9.82e-05\n",
      "feature_10    -0.0017      0.001     -2.974      0.003      -0.003      -0.001\n",
      "feature_11   4.54e-05   9.74e-06      4.659      0.000    2.63e-05    6.45e-05\n",
      "feature_12    -0.0101      0.004     -2.322      0.020      -0.019      -0.002\n",
      "feature_13    -0.0021      0.003     -0.614      0.540      -0.009       0.005\n",
      "feature_14     0.0094      0.004      2.372      0.018       0.002       0.017\n",
      "feature_20    -0.0030      0.001     -2.032      0.042      -0.006      -0.000\n",
      "feature_22     0.0093      0.002      5.210      0.000       0.006       0.013\n",
      "feature_23    -0.0044      0.002     -1.918      0.055      -0.009    9.53e-05\n",
      "feature_24    -0.0129      0.003     -4.651      0.000      -0.018      -0.007\n",
      "feature_25    -0.0049      0.002     -2.478      0.013      -0.009      -0.001\n",
      "feature_28    -0.0080      0.002     -4.309      0.000      -0.012      -0.004\n",
      "feature_29     0.0231      0.004      6.532      0.000       0.016       0.030\n",
      "feature_30    -0.0226      0.003     -7.668      0.000      -0.028      -0.017\n",
      "feature_34    -0.0056      0.002     -2.473      0.013      -0.010      -0.001\n",
      "feature_35    -0.0046      0.002     -2.073      0.038      -0.009      -0.000\n",
      "feature_36     0.0002      0.001      0.168      0.866      -0.002       0.002\n",
      "feature_37     0.0064      0.002      3.539      0.000       0.003       0.010\n",
      "feature_38     0.0063      0.002      3.564      0.000       0.003       0.010\n",
      "feature_48     0.0017      0.001      2.636      0.008       0.000       0.003\n",
      "feature_49    -0.0013      0.001     -1.706      0.088      -0.003       0.000\n",
      "feature_59     0.0527      0.001     37.013      0.000       0.050       0.055\n",
      "feature_60     0.0507      0.002     31.673      0.000       0.048       0.054\n",
      "feature_61    -0.0035      0.001     -3.169      0.002      -0.006      -0.001\n",
      "feature_67     0.0166      0.003      5.078      0.000       0.010       0.023\n",
      "feature_68     0.0346      0.002     14.016      0.000       0.030       0.039\n",
      "feature_69     0.0174      0.003      5.800      0.000       0.012       0.023\n",
      "feature_70    -0.0256      0.003     -8.504      0.000      -0.032      -0.020\n",
      "feature_71    -0.0175      0.002     -8.212      0.000      -0.022      -0.013\n",
      "feature_72     0.0005      0.003      0.188      0.851      -0.005       0.006\n",
      "feature_77     0.0052      0.004      1.176      0.240      -0.003       0.014\n",
      "feature_78    -0.0117      0.004     -2.611      0.009      -0.021      -0.003\n",
      "feature_47    -0.0002      0.001     -0.249      0.803      -0.001       0.001\n",
      "==============================================================================\n",
      "Omnibus:                   134407.762   Durbin-Watson:                   1.962\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1553378.999\n",
      "Skew:                           0.254   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.172   Cond. No.                     1.67e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.67e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final_model, mse, r2\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Train and evaluate for target_1\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m model_1, mse_1, r2_1 \u001b[38;5;241m=\u001b[39m fit_and_evaluate(y_train_1, y_test_1, weights_train, weights_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Train and evaluate for target_2\u001b[39;00m\n\u001b[0;32m     88\u001b[0m model_2, mse_2, r2_2 \u001b[38;5;241m=\u001b[39m fit_and_evaluate(y_train_2, y_test_2, weights_train, weights_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 53\u001b[0m, in \u001b[0;36mfit_and_evaluate\u001b[1;34m(y_train, y_test, weights_train, weights_test, target_name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOLS Summary for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, ols_model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# White's test for heteroscedasticity\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m white_test \u001b[38;5;241m=\u001b[39m het_white(ols_model\u001b[38;5;241m.\u001b[39mresid, X_train)\n\u001b[0;32m     54\u001b[0m p_value \u001b[38;5;241m=\u001b[39m white_test[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Second value is the p-value\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhite\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Test p-value for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Garv\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\diagnostic.py:867\u001b[0m, in \u001b[0;36mhet_white\u001b[1;34m(resid, exog)\u001b[0m\n\u001b[0;32m    862\u001b[0m lm \u001b[38;5;241m=\u001b[39m nobs \u001b[38;5;241m*\u001b[39m resols\u001b[38;5;241m.\u001b[39mrsquared\n\u001b[0;32m    863\u001b[0m \u001b[38;5;66;03m# Note: degrees of freedom for LM test is nvars minus constant\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# degrees of freedom take possible reduced rank in exog into account\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;66;03m# df_model checks the rank to determine df\u001b[39;00m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;66;03m# extra calculation that can be removed:\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m resols\u001b[38;5;241m.\u001b[39mdf_model \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mmatrix_rank(exog) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    868\u001b[0m lmpval \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mchi2\u001b[38;5;241m.\u001b[39msf(lm, resols\u001b[38;5;241m.\u001b[39mdf_model)\n\u001b[0;32m    869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lm, lmpval, fval, fpval\n",
      "File \u001b[1;32mc:\\Users\\Garv\\anaconda3\\Lib\\site-packages\\numpy\\linalg\\linalg.py:1922\u001b[0m, in \u001b[0;36mmatrix_rank\u001b[1;34m(A, tol, hermitian)\u001b[0m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(A\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m-> 1922\u001b[0m S \u001b[38;5;241m=\u001b[39m svd(A, compute_uv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, hermitian\u001b[38;5;241m=\u001b[39mhermitian)\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1924\u001b[0m     tol \u001b[38;5;241m=\u001b[39m S\u001b[38;5;241m.\u001b[39mmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mmax\u001b[39m(A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]) \u001b[38;5;241m*\u001b[39m finfo(S\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39meps\n",
      "File \u001b[1;32mc:\\Users\\Garv\\anaconda3\\Lib\\site-packages\\numpy\\linalg\\linalg.py:1693\u001b[0m, in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[0;32m   1690\u001b[0m     gufunc \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39msvd_n\n\u001b[0;32m   1692\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->d\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1693\u001b[0m s \u001b[38;5;241m=\u001b[39m gufunc(a, signature\u001b[38;5;241m=\u001b[39msignature, extobj\u001b[38;5;241m=\u001b[39mextobj)\n\u001b[0;32m   1694\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "from sklearn.metrics import r2_score  # For R² calculation\n",
    "\n",
    "# Select only feature columns\n",
    "# Find feature columns that exist in both train and test sets\n",
    "feature_cols = [\n",
    "    col for col in train_df.columns if col.startswith(\"feature_\") and col in test_df.columns\n",
    "]\n",
    "\n",
    "# Select features from both datasets\n",
    "# Select features from both datasets\n",
    "X_train = train_df[feature_cols].copy()\n",
    "X_test = test_df[feature_cols].copy()\n",
    "\n",
    "# Handle NaNs or infinite values\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Add constant term for the intercept\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# Ensure y_train and weights match the filtered X_train\n",
    "train_df = train_df.loc[X_train.index]  # Keep only valid rows\n",
    "test_df = test_df.loc[X_test.index]\n",
    "\n",
    "# Targets\n",
    "y_train_1 = train_df[\"target_1\"]\n",
    "y_train_2 = train_df[\"target_2\"]\n",
    "y_test_1 = test_df[\"target_1\"]\n",
    "y_test_2 = test_df[\"target_2\"]\n",
    "\n",
    "# Weights column\n",
    "weights_train = train_df[\"weight\"]\n",
    "weights_test = test_df[\"weight\"]\n",
    "\n",
    "# Add constant for intercept\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# Function to fit OLS, check heteroscedasticity, apply WLS if needed, and compute metrics\n",
    "def fit_and_evaluate(y_train, y_test, weights_train, weights_test, target_name):\n",
    "    print(f\"\\nTraining model for {target_name}...\\n\")\n",
    "    \n",
    "    # Fit OLS\n",
    "    ols_model = sm.OLS(y_train, X_train).fit()\n",
    "    print(f\"OLS Summary for {target_name}:\\n\", ols_model.summary())\n",
    "\n",
    "    # White's test for heteroscedasticity\n",
    "    white_test = het_white(ols_model.resid, X_train)\n",
    "    p_value = white_test[1]  # Second value is the p-value\n",
    "    print(f\"White's Test p-value for {target_name}: {p_value}\")\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        print(f\"Heteroscedasticity detected in {target_name}. Applying WLS...\")\n",
    "        wls_model = sm.WLS(y_train, X_train, weights=1/weights_train).fit()\n",
    "        print(f\"WLS Summary for {target_name}:\\n\", wls_model.summary())\n",
    "        final_model = wls_model\n",
    "    else:\n",
    "        print(f\"No heteroscedasticity detected in {target_name}. Using OLS.\")\n",
    "        final_model = ols_model\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = final_model.predict(X_test)\n",
    "\n",
    "    # Apply sqrt(weights) transformation to both actual and predicted values\n",
    "    sqrt_weights_test = np.sqrt(weights_test)\n",
    "    y_test_scaled = y_test * sqrt_weights_test\n",
    "    y_pred_scaled = y_pred * sqrt_weights_test\n",
    "\n",
    "    # Compute Weighted MSE\n",
    "    mse = np.mean(weights_test * (y_test - y_pred) ** 2)\n",
    "    print(f\"Weighted MSE for {target_name}: {mse:.4f}\")\n",
    "\n",
    "    # Compute R² on transformed values\n",
    "    r2 = r2_score(y_test_scaled, y_pred_scaled)\n",
    "    print(f\"R² on test set for {target_name}: {r2:.4f}\")\n",
    "\n",
    "    return final_model, mse, r2\n",
    "\n",
    "# Train and evaluate for target_1\n",
    "model_1, mse_1, r2_1 = fit_and_evaluate(y_train_1, y_test_1, weights_train, weights_test, \"target_1\")\n",
    "\n",
    "# Train and evaluate for target_2\n",
    "model_2, mse_2, r2_2 = fit_and_evaluate(y_train_2, y_test_2, weights_train, weights_test, \"target_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feature columns present in both train_df and test_df\n",
    "feature_cols = [\n",
    "    col for col in train_df.columns if col.startswith(\"feature_\") and col in test_df.columns\n",
    "]\n",
    "\n",
    "# Select features from both datasets\n",
    "X_train = train_df[feature_cols].copy()\n",
    "X_test = test_df[feature_cols].copy()\n",
    "\n",
    "# Handle NaNs or infinite values\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Add constant term for the intercept\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# Ensure y_train and weights match the filtered X_train\n",
    "train_df = train_df.loc[X_train.index]  # Keep only valid rows\n",
    "test_df = test_df.loc[X_test.index]\n",
    "\n",
    "# Targets\n",
    "y_train_1 = train_df[\"target_1\"]\n",
    "y_train_2 = train_df[\"target_2\"]\n",
    "y_test_1 = test_df[\"target_1\"]\n",
    "y_test_2 = test_df[\"target_2\"]\n",
    "\n",
    "# Weights column\n",
    "weights_train = train_df[\"weights\"]\n",
    "weights_test = test_df[\"weights\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
